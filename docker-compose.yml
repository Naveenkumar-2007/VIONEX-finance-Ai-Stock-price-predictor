# Docker Compose Configuration
# Run with: docker-compose up -d

version: '3.8'

services:
  # Main Flask Application
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: vionex-stock-predictor
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - PYTHONUNBUFFERED=1
      - MODEL_PATH=/app/artifacts/stock_lstm_model.h5
    volumes:
      - ./artifacts:/app/artifacts
      - ./mlops/model_registry:/app/mlops/model_registry
      - ./mlops/logs:/app/mlops/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - vionex-network
  
  # Background Worker for Model Training
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: vionex-worker
    command: python mlops/scheduler.py
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ./artifacts:/app/artifacts
      - ./mlops/model_registry:/app/mlops/model_registry
      - ./mlops/logs:/app/mlops/logs
    restart: unless-stopped
    depends_on:
      - web
    networks:
      - vionex-network
  
  # MLflow Tracking Server (Optional)
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: vionex-mlflow
    ports:
      - "5001:5000"
    command: mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlflow/artifacts
    volumes:
      - ./mlruns:/mlflow/artifacts
      - mlflow-db:/mlflow
    restart: unless-stopped
    networks:
      - vionex-network

networks:
  vionex-network:
    driver: bridge

volumes:
  mlflow-db:
