# ðŸš€ Azure Deployment Solution - Stock Price Predictor

## ðŸ“‹ Problem Analysis (Based on Azure Logs)

### Issues Identified:
1. **Worker Timeout During TensorFlow Loading**
   - Gunicorn workers were booting successfully
   - Workers crashed while loading TensorFlow and LSTM model
   - Default timeout (30s) was too short for model initialization
   - TensorFlow initialization messages appeared in logs but app returned 503

2. **Memory and Resource Constraints**
   - Multiple workers loading TensorFlow simultaneously consumed excessive memory
   - Azure Basic tier has limited resources
   - Each worker attempted to load the large LSTM model file (~several MB)

3. **Startup Configuration Issues**
   - Startup command didn't optimize for ML model loading
   - No preloading strategy causing repeated model loads
   - Insufficient logging for diagnostics

## âœ… Solutions Implemented

### 1. **Optimized Gunicorn Configuration** (`gunicorn_config.py`)
```python
# Key settings:
workers = 1                # Single worker to avoid multiple model loads
timeout = 600              # 10 minutes for model initialization
preload_app = True         # Load app once before forking workers
worker_class = 'sync'      # Synchronous worker (stable for ML)
loglevel = 'info'          # Detailed logging
```

**Why this works:**
- Single worker reduces memory footprint
- Extended timeout allows TensorFlow to initialize fully
- Preloading loads model once, then forks worker (memory efficient)
- Comprehensive logging helps diagnose any issues

### 2. **Lazy Loading for TensorFlow** (`app.py`)
```python
# Before: Loaded on module import (crashed workers)
from tensorflow.keras.models import load_model
model = load_model(MODEL_PATH)

# After: Loaded only when prediction endpoint called
def load_lstm_model():
    if model_loading_attempted:
        return model
    # Import TensorFlow only when needed
    from tensorflow.keras.models import load_model
    model = load_model(MODEL_PATH)
    return model
```

**Why this works:**
- Workers can boot quickly without waiting for TensorFlow
- Model loads only when first prediction is requested
- Reduces startup time from 30+ seconds to <5 seconds
- Prevents worker timeout during initialization

### 3. **Updated Startup Command** (`startup.txt`)
```bash
gunicorn wsgi:app --bind=0.0.0.0:8000 --timeout 600 --workers 1 --worker-class sync --preload --log-level info
```

**Why this works:**
- Explicit parameters ensure proper configuration
- Timeout of 600s gives TensorFlow ample time
- Single worker optimized for Azure Basic tier
- Info logging provides visibility

### 4. **Local Import of scikit-learn**
```python
# Import MinMaxScaler locally in prediction functions
def predict_multi_day_lstm(hist, current_price, days):
    from sklearn.preprocessing import MinMaxScaler
    # ... prediction logic
```

**Why this works:**
- Reduces import time during app initialization
- Only imports when prediction is actually called
- Helps workers boot faster

## ðŸ“Š Expected Behavior After Deployment

### First Request (Cold Start):
1. â±ï¸ **0-5s**: Gunicorn worker boots successfully
2. â±ï¸ **5-10s**: Flask app initializes (routes, templates)
3. â±ï¸ **When prediction called**: TensorFlow loads (~30-40s)
4. âœ… **Model ready**: Subsequent predictions are fast (<1s)

### Subsequent Requests:
- âš¡ **Instant**: Model already loaded in memory
- ðŸš€ **<1 second**: Predictions return quickly

## ðŸ” Monitoring & Verification

### Check Deployment Status:
```powershell
# View GitHub Actions workflow
Visit: https://github.com/Naveenkumar-2007/VIONEX-finance-Ai-Stock-price-predictor/actions

# Stream Azure logs
az webapp log tail --resource-group stock --name VIONEX-finance-Ai-Stock-price-predictor
```

### Look for these SUCCESS indicators in logs:
```
âœ… "[INFO] Starting gunicorn 21.2.0"
âœ… "[INFO] Listening at: http://0.0.0.0:8000"
âœ… "[INFO] Booting worker with pid: XXXX"
âœ… "ðŸ“¦ Loading TensorFlow model from artifacts/stock_lstm_model.h5..."
âœ… "âœ“ Model loaded successfully"
```

### Test the app:
```powershell
# Test homepage
Invoke-WebRequest -Uri "https://vionex-finance-ai-stock-price-predictor-auggekghbghye0f4.centralindia-01.azurewebsites.net"

# Test stock prediction API (first request may take 30-40s)
Invoke-WebRequest -Uri "https://vionex-finance-ai-stock-price-predictor-auggekghbghye0f4.centralindia-01.azurewebsites.net/api/stock_data/AAPL?days=3"
```

## ðŸŽ¯ Key Changes Summary

| File | Change | Impact |
|------|--------|--------|
| `startup.txt` | Optimized Gunicorn params | Increased timeout, single worker, preload |
| `gunicorn_config.py` | Production config | Memory-efficient, comprehensive logging |
| `app.py` | Lazy TensorFlow loading | Faster worker boot, no timeout crashes |
| `app.py` | Local sklearn imports | Reduced initialization overhead |

## âš™ï¸ Technical Details

### Why Workers Were Timing Out:

**Old Flow:**
```
1. Gunicorn starts worker â†’ 
2. Worker imports app.py â†’ 
3. app.py imports TensorFlow (30s) â†’ 
4. app.py loads LSTM model (10s) â†’ 
5. TIMEOUT! Worker killed at 30s â†’ 
6. 503 Error
```

**New Flow:**
```
1. Gunicorn starts worker â†’ 
2. Worker imports app.py (5s) â†’ 
3. Worker ready! âœ… â†’ 
4. First prediction request arrives â†’ 
5. Load TensorFlow + model (40s within 600s timeout) â†’ 
6. Success! âœ…
```

### Memory Optimization:

**Old:** 2 workers Ã— TensorFlow + Model = ~2GB RAM
**New:** 1 worker Ã— TensorFlow + Model = ~1GB RAM

Azure Basic tier provides 1.75GB RAM - single worker fits comfortably.

## ðŸš¨ Troubleshooting

### If still getting 503:
1. **Wait 2-3 minutes** after deployment for cold start
2. Check GitHub Actions completed successfully
3. Verify logs show "Model loaded successfully"
4. Ensure `artifacts/stock_lstm_model.h5` exists in deployment

### If first request times out:
- This is expected! TensorFlow loading takes 30-40 seconds
- Refresh the page after 1 minute
- Model will be cached for subsequent requests

### To verify model file exists:
```powershell
az webapp ssh --resource-group stock --name VIONEX-finance-Ai-Stock-price-predictor
# Then in SSH:
ls -lh artifacts/stock_lstm_model.h5
```

## ðŸ“ Next Steps

1. âœ… **GitHub Actions will auto-deploy** (~20-25 minutes)
2. â±ï¸ **Wait for deployment to complete**
3. ðŸ” **Monitor Azure logs** for successful worker boot
4. ðŸ§ª **Test homepage first** (should load immediately)
5. ðŸŽ¯ **Test prediction endpoint** (first call takes 30-40s, then fast)

## ðŸŽ‰ Success Indicators

Your app is working when you see:
- âœ… Homepage loads with dashboard
- âœ… Azure logs show "Model loaded successfully"
- âœ… Stock prediction API returns JSON data
- âœ… No worker restart messages in logs

## ðŸ“ž If Issues Persist

Check:
1. Is `artifacts/stock_lstm_model.h5` in your GitHub repo? (Should be tracked by Git LFS or committed)
2. Does GitHub Actions build succeed?
3. Do Azure logs show any Python errors or tracebacks?
4. Is Azure Web App using Python 3.12 runtime?

---

**Deployment initiated:** October 24, 2025
**Commit:** 7a8dfad
**Expected completion:** ~25 minutes from push
